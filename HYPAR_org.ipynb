{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages and API Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Only needs to be run upon first-time use\n",
    "import sys\n",
    "!{sys.executable} -m pip install alpha_vantage\n",
    "!{sys.executable} -m pip install quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import itertools as it\n",
    "import pandas as pd\n",
    "import cmath as c\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import datetime as dt\n",
    "import quandl as q\n",
    "import time\n",
    "# https://github.com/RomelTorres/alpha_vantage\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from alpha_vantage.techindicators import TechIndicators \n",
    "from alpha_vantage.sectorperformance import SectorPerformances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alpha Vantage API keys\n",
    "API_URL = 'https://www.alphavantage.co/query?'\n",
    "API_KEY1 = 'TMANNBF5NO707ZEI'\n",
    "API_KEY2 = 'AO48IFCXLA3BX1O9'\n",
    "API_KEY3 = 'GDJZQ31AX2TZRFA1'\n",
    "API_KEY4 = 'APHZP2X3GZ7UQ7NO'\n",
    "API_KEY5 = 'X9LEOT46QKZHC0O9'\n",
    "\n",
    "# Quandl API key\n",
    "q.ApiConfig.api_key = \"ntUKZwApL5qnmU9pk_rB\"\n",
    "\n",
    "# Output formats: json dictionaries (default), DataFrame, csv.\n",
    "# csv does not support ForeignExchange, SectorPerformances, TechIndicators.\n",
    "# indexing_type can also be integer (default: date)\n",
    "ts_dct = [TimeSeries(key=API_KEY1, output_format='pandas', indexing_type='date'), \n",
    "       TimeSeries(key=API_KEY2, output_format='pandas', indexing_type='date'), \n",
    "       TimeSeries(key=API_KEY3, output_format='pandas', indexing_type='date'),\n",
    "       TimeSeries(key=API_KEY4, output_format='pandas', indexing_type='date'),\n",
    "       TimeSeries(key=API_KEY5, output_format='pandas', indexing_type='date')]\n",
    "\n",
    "ti_dct = [TechIndicators(key=API_KEY1, output_format='pandas', indexing_type='date'), \n",
    "       TechIndicators(key=API_KEY2, output_format='pandas', indexing_type='date'), \n",
    "       TechIndicators(key=API_KEY3, output_format='pandas', indexing_type='date'),\n",
    "       TechIndicators(key=API_KEY4, output_format='pandas', indexing_type='date'),\n",
    "       TechIndicators(key=API_KEY5, output_format='pandas', indexing_type='date')]\n",
    "\n",
    "sp_dct = [SectorPerformances(key=API_KEY1, output_format='pandas', indexing_type='date'), \n",
    "       SectorPerformances(key=API_KEY2, output_format='pandas', indexing_type='date'), \n",
    "       SectorPerformances(key=API_KEY3, output_format='pandas', indexing_type='date'),\n",
    "       SectorPerformances(key=API_KEY4, output_format='pandas', indexing_type='date'),\n",
    "       SectorPerformances(key=API_KEY5, output_format='pandas', indexing_type='date')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the primary method for retrieving data from the AlphaVantage API. Rather than worrying about all of the individual data collection methods, this method allows the user to just specify the key parameters, and the appropriate API method retrieves the data. Because the API only allows for 5 calls/minute, each block of ticker calls can be made one at a time every minute. Thus, **`collect()` is HIGHLY RECOMMENDED** as it prevents errors related to exceeding the 5 calls/minute rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global port\n",
    "global port_rets\n",
    "\n",
    "port = {} # Stores all stock data\n",
    "port_rets = {} # Stores all return data\n",
    "\n",
    "# Used to get individual stock data from the AlphaVantage API.\n",
    "# symbols: list of stock tickers as strings\n",
    "# start_date, end_date: string of date 'YYYY-MM-DD'\n",
    "# intra_int: intraday interval; '1min', '5min', '15min', '30min', '60min' (default '15min')\n",
    "# add: by default adds the searched asset to the portfolio.\n",
    "# api_num: index to reference of ts_dct; relevant when pulling more than 5 stocks at once\n",
    "def get_data(symbol, start_date= None, end_date= None, \n",
    "             int_type='daily_adjusted', intra_int='15min', add=True, api_key=ts_dct[0]):\n",
    "    \n",
    "    if int_type is 'daily_adjusted':\n",
    "        data, meta = api_key.get_daily_adjusted(symbol=symbol, outputsize='full')\n",
    "    else: \n",
    "        data, meta = api_key.get_intraday(symbol=symbol, interval=intra_int, outputsize='full')\n",
    "\n",
    "    # Remove numbers from column labels.\n",
    "    data.rename(columns=lambda col: col[3:], inplace=True)\n",
    "\n",
    "    # Filter the DataFrame to contain only those specified by the start and end dates.\n",
    "    if start_date and end_date:\n",
    "        data = data.loc[start_date:end_date]\n",
    "    elif start_date:\n",
    "        data = data.loc[start_date:]\n",
    "    else:\n",
    "        data = data.loc[:end_date]\n",
    "\n",
    "    # Add the stock data to a DataFrame and reindex to be DateTime indices.\n",
    "    df_stock = pd.DataFrame(data)\n",
    "    df_stock.index = pd.to_datetime(df_stock.index)\n",
    "\n",
    "    # By default, add to the portfolio\n",
    "    if add:\n",
    "        port[symbol] = df_stock\n",
    "\n",
    "    return pd.DataFrame(df_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to calculate the daily percent change, log returns, and\n",
    "# cumulative returns ovhttp://localhost:8888/notebooks/Desktop/Hesiod%20Financial/LKQ%20(April%2014%202019).ipynb#er time for each stock in the portfolio.\n",
    "# portfolio: may refer to portfolio containing all stocks or an \n",
    "# individual stock\n",
    "# symbol: specify ticker as string if calculating an individual \n",
    "# stock's returns not already in the portfolio\n",
    "def calculate_returns(portfolio, symbol=None):\n",
    "\n",
    "    # True if the portfolio is a dictionary containing multiple stocks.\n",
    "    if type(portfolio) is type({1:2}):\n",
    "        for symb, data in portfolio.items():\n",
    "\n",
    "            # Get price close data.\n",
    "            daily_close = data['close']\n",
    "\n",
    "            # Calculate percent change for each period.\n",
    "            daily_pct_change = daily_close.pct_change()\n",
    "            daily_pct_change.fillna(0, inplace=True)\n",
    "\n",
    "            # Calculate log returns for each period.\n",
    "            daily_log_returns = np.log(daily_close.pct_change()+1)\n",
    "            daily_log_returns.fillna(0, inplace=True)\n",
    "\n",
    "            # Cumulative daily rate of return is useful to determine the \n",
    "            # value of an investment at regular intervals.\n",
    "            cum_daily_return = (1 + daily_pct_change).cumprod()\n",
    "            port_rets[symb] = pd.DataFrame({'pct change': daily_pct_change, \n",
    "                                       'log returns':daily_log_returns, \n",
    "                                       'cumulative daily':cum_daily_return})\n",
    "        return port_rets[symb]\n",
    "\n",
    "    # True if only calculating for one stock.\n",
    "    else:\n",
    "        daily_close = portfolio['close']\n",
    "        daily_pct_change = daily_close.pct_change()\n",
    "        daily_pct_change.fillna(0, inplace=True)\n",
    "\n",
    "        daily_log_returns = np.log(daily_close.pct_change()+1)\n",
    "        daily_log_returns.fillna(0, inplace=True)\n",
    "\n",
    "        # Cumulative daily rate of return is useful to determine \n",
    "        # the value of an investment at regular intervals.\n",
    "        cum_daily_return = (1 + daily_pct_change).cumprod()\n",
    "        port_rets[symbol] = pd.DataFrame({'pct change': daily_pct_change, \n",
    "                                       'log returns':daily_log_returns, \n",
    "                                       'cumulative daily':cum_daily_return})\n",
    "        return port_rets[symbol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary method for acquring stock data. Recommended over get_data() because\n",
    "# it avoids the 5 API calls/min limitation by inherently waiting 1 minute if\n",
    "# more than 5 stocks are being called at once.\n",
    "# tickers: list of ticker strings\n",
    "# start_date, end_date: string of date 'YYYY-MM-DD'\n",
    "def collect(tickers, start=None, end=None, add_to_port=True):   \n",
    "    # Partition list of tickers into sub-lists of 4 tickers.\n",
    "    grouped_ticks = [tickers[i*5:(i+1)*5] for i in range(\n",
    "        (len(tickers)+ 4)// 5)]\n",
    "    # If there are more than 1 paritions, call each partition\n",
    "    # one at a time and use one API key to get the data.\n",
    "    if 1 < len(grouped_ticks) <= len(ts_dct):\n",
    "        for group in grouped_ticks:\n",
    "            sub_collect(group=group, add_to_port=add_to_port)\n",
    "    elif len(grouped_ticks) > len(ts_dct):\n",
    "        print(f'Max number of tickers callable at once: {len(ts_dct)*5}')\n",
    "    else:\n",
    "        sub_collect(group=grouped_ticks.pop(), add_to_port=add_to_port)\n",
    "# Helper method for collect(). Iterates through list of grouped tickers\n",
    "# and calls to get the stock data for each ticker.\n",
    "def sub_collect(group, add_to_port=True):\n",
    "    for g, api in zip(group, ts_dct):\n",
    "        get_data(symbol=g, start_date=start, end_date=end, add=add_to_port, api_key=api)\n",
    "        time.sleep(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the Portfolio and Timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tickers = ['EPD', 'HRTX', 'PAGS', 'QQQ', 'COMM', 'ACM', 'SPY', 'LKQ', 'ZUO']\n",
    "\n",
    "today = dt.datetime.today()\n",
    "\n",
    "# Enter start date (default set to 1 year ago)\n",
    "start = dt.datetime(today.year - 1, today.month, today.day).strftime('%Y-%m-%d')\n",
    "\n",
    "# Default set to today\n",
    "end = today.strftime('%Y-%m-%d')\n",
    "\n",
    "collect(tickers, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calculate_returns(port);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ticker: stock symbol\n",
    "# price_type: 'adjusted close' (default), 'close', 'open'\n",
    "# Returns matplotlib objects as well\n",
    "def plot_returns(ticker, price_type='adjusted close'):\n",
    "\n",
    "    # Plot price action\n",
    "    price = port[ticker][price_type].plot(\n",
    "        figsize=(15,3), label=ticker, legend=False)\n",
    "    plt.title(f'{ticker} Historical Price Action')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot daily pct change\n",
    "    pct_change = port_rets[ticker]['pct change'].plot(\n",
    "        figsize=(15,3), label=ticker,legend=False)\n",
    "    plt.title(f'{ticker} Daily Percent Change')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Daily Percent Return')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot cumulative returns\n",
    "    cum_daily = port_rets[ticker]['cumulative daily'].plot(\n",
    "        figsize=(15,3), label=ticker,legend=False)\n",
    "    plt.title(f'{ticker} Cumulative Daily Returns')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Cumulative Percent Return')\n",
    "    plt.show()\n",
    "\n",
    "    return price, pct_change, cum_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_returns('ZUO');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_cdf(ticker):\n",
    "    \n",
    "    r = port_rets[ticker]['pct change']  \n",
    "    ax = sns.distplot(r,\n",
    "                      rug=True,\n",
    "                      hist_kws=dict(cumulative=True), \n",
    "                      kde_kws=dict(cumulative=True))\n",
    "    ax.set_title(ticker + ' CDF')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_xlabel('% Change of Returns')\n",
    "    plt.show()\n",
    "    \n",
    "    moments = pd.DataFrame(columns=['Mean', \n",
    "                                    'SD', \n",
    "                                    'Skew', \n",
    "                                    'Kurtosis',\n",
    "                                   'Normal (JB)'])\n",
    "    \n",
    "    vals = pd.Series([float('%.3f'%(r.mean())),\n",
    "                         float('%.3f'%(r.std())),\n",
    "                         float('%.3f'%(r.skew())),\n",
    "                         float('%.3f'%(r.kurtosis())),\n",
    "                         stats.jarque_bera(r)[1] > 0.05],\n",
    "                        index=moments.columns).rename('')\n",
    "    moments = moments.append(vals)\n",
    "    \n",
    "    return moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cdf('ZUO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the volatility (i.e. standard deviation) of an asset in the portfolio.\n",
    "# show_price: if True, also plots price data of the stock.\n",
    "# show_benchmark: if True, also plots volatility of S&P 500.\n",
    "def plot_volatility(ticker, min_periods=25, show_price=False, show_bench=False):\n",
    "    \n",
    "    global price, bench_vol\n",
    "    price= None\n",
    "    bench_vol= None\n",
    "\n",
    "    # Get the asset volatility and optionally the S&P volatility and price data of the asset.    \n",
    "    vol = port_rets[ticker]['pct change'].rolling(min_periods).std()*np.sqrt(min_periods)\n",
    "    if show_bench:\n",
    "        start = str(port_rets[ticker].index[0])[:-9]\n",
    "        end = str(port_rets[ticker].index[-1])[:-9]\n",
    "        bench_data = port['SPY']\n",
    "        bench_rets = port_rets['SPY']\n",
    "        bench_vol = bench_rets['pct change'].rolling(min_periods).std()*np.sqrt(min_periods)\n",
    "    if show_price:\n",
    "        price = port[ticker]['close']\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(12,3))\n",
    "    \n",
    "    vol_color = 'tab:red'\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Percent')\n",
    "    ax1.plot(vol, color=vol_color, label=ticker)\n",
    "    ax1.legend(loc=1)\n",
    "    \n",
    "    if show_bench:\n",
    "        bench_color='tab:orange'\n",
    "        ax1.plot(bench_vol, color=bench_color, label='S&P')\n",
    "        ax1.legend(loc=1)\n",
    "    if show_price:\n",
    "        ax2 = ax1.twinx() # second axes with same x-axis\n",
    "        price_color = 'tab:blue'\n",
    "        ax2.set_ylabel(f'{ticker} Price')\n",
    "        ax2.plot(price, color=price_color, label=f'{ticker} price')\n",
    "        ax2.tick_params(axis='y', labelcolor=price_color)\n",
    "        ax2.legend(loc=2)\n",
    "    vol.dropna()\n",
    "    asset_mean = vol.mean()\n",
    "    asset_std_dev = vol.std()\n",
    "    asset_std_err = vol.sem()\n",
    "    \n",
    "    bench_mean = bench_vol.mean()\n",
    "    bench_std_dev = bench_vol.std()\n",
    "    bench_std_err = bench_vol.sem()\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.title(f'{ticker} vs. S&P: Volatility ({min_periods}-Day Rolling Period)')\n",
    "    plt.show()\n",
    "        \n",
    "    vol_stats = pd.DataFrame(index=['mean', 'std dev', 'std err'])\n",
    "    vol_stats[ticker] = pd.Series((asset_mean, asset_std_dev, asset_std_err), index=vol_stats.index)\n",
    "    vol_stats['S&P 500'] = pd.Series((bench_mean, bench_std_dev, bench_std_err), index=vol_stats.index)\n",
    "    \n",
    "    agree=False\n",
    "    if asset_mean <= bench_mean and asset_mean + asset_std_err >= bench_mean:\n",
    "        agree = True\n",
    "    elif asset_mean >= bench_mean and asset_mean - asset_std_err <= bench_mean:\n",
    "        agree=True\n",
    "    \n",
    "    print(vol_stats) \n",
    "    print(f'S&P and {ticker} agree within std error: {agree}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_volatility('EPD', min_periods=20, show_bench=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = str(list(port_rets.values())[0].index[0])[:-9]\n",
    "end = str(list(port_rets.values())[0].index[-1])[:-9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_linreg(ticker_1, ticker_2, \n",
    "                price_type='close',\n",
    "                visible=True):\n",
    "    \n",
    "    params = stats.linregress(port[ticker_1][price_type],\n",
    "                    port[ticker_2][price_type])\n",
    "        \n",
    "    if visible:\n",
    "        ax = sns.regplot(x=port[ticker_1][price_type], \n",
    "                y=port[ticker_2][price_type])\n",
    "        ax.set_xlabel(ticker_1)\n",
    "        ax.set_ylabel(ticker_2)\n",
    "        start = port[ticker_1].index[0].strftime('%Y-%m-%d')\n",
    "        end = port[ticker_1].index[-1].strftime('%Y-%m-%d')\n",
    "        ax.set_title(f'{ticker_1}-{ticker_2} LR ({start} - {end})')\n",
    "        plt.show()\n",
    "    \n",
    "    vals = pd.DataFrame(columns=['R squared', 'p value', 'std err'])\n",
    "    \n",
    "    v = pd.Series([float('%.3f'%(params.rvalue**2)), \n",
    "                   float('%.3f'%(params.pvalue)), \n",
    "                   float('%.3f'%(params.stderr))],\n",
    "                  index=vals.columns).rename('')\n",
    "    vals = vals.append(v)\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_heatmap():\n",
    "    \n",
    "    col = []\n",
    "    \n",
    "    for sym, data in port.items():\n",
    "        row = []\n",
    "        \n",
    "        for s, d in port.items():\n",
    "            r = np.corrcoef(d['close'], data['close'])[0][1]\n",
    "            row.append(r)\n",
    "    \n",
    "        col.append(row)\n",
    "        \n",
    "    corr_matrix = pd.DataFrame(col, columns=port.keys())\n",
    "    corr_matrix.index = port.keys()\n",
    "    \n",
    "    mask = np.zeros_like(corr_matrix)\n",
    "    mask[np.triu_indices_from(mask)]=True\n",
    "    ax = sns.heatmap(corr_matrix, \n",
    "                     annot=True,\n",
    "                     mask=mask,\n",
    "                     cmap='RdYlGn_r')\n",
    "    ax.set_title('Portfolio Correlation Heat Map')\n",
    "    return corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_scatter_matrix():\n",
    "    \n",
    "    close = pd.DataFrame()\n",
    "    for s, d in port.items():\n",
    "        close[s] = port[s]['close']\n",
    "    #pd.plotting.scatter_matrix(close, \n",
    "    #                           alpha=0.2,\n",
    "    #                           figsize=(10,10), \n",
    "    #                           diagonal='kde');\n",
    "        # plt.title('Portfolio Scatter Matrix')\n",
    "        # plt.show()\n",
    "    ax = sns.pairplot(close)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_scatter_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusted for Skewness and Kurtosis Sharpe Ratio (ASKSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a gross oversimplification of the problem that arises with using the standard mean-variance-based Sharpe Ratio. When using the Sharpe Ratio to determine the \"risk-reward\" value of owning an asset or portfolio of assets, it is assumed that the return data is normally distributed. However, this is almost never the case, so the value of the Sharpe Ratio can be misleading. To account for this, Zakamouline and Koekebakker (2008) authored an article deriving a parametric form of a special-case form of the generalized Sharpe Ratio that accounts for higher-order moments of distribution than just mean and variance. That is, the returns are not assumed to be normally disributed, so the ASKSR accounts for skewness (3rd moment) and kurtossis (4th moment) of the returns distribution of an asset. To read more into the \"nitty-gritty,\" click on the link below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1028715"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors chose to use the normal inverse Gaussian distribution (NIGD) because:\n",
    "1. NIGD has an explicit expression for the probability density function\n",
    "2. Distributions of risky asset returns can be often fitted extremely well by the NIGD\n",
    "3. For the NIGD, there are explicit formulas for finding the parameters of the distribution via the values of the first four moments of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\eta$ and $\\delta$ are ordinary paramters of location and scale whereas $\\alpha$ and $\\beta$ determine the shape of the density. In particular, $\\beta$ determines the degree of skewwness.\n",
    "\n",
    "For symmetrical densities, $\\beta = 0$. The conditions for a viable NIG density are $\\delta > 0$, $\\alpha > 0$, and $\\frac{\\vert \\beta \\vert}{\\alpha} < 1$. Note that to get meaningful parameters of the NIGD, the following conditions must be satisfied:\n",
    "\n",
    "\\begin{align}\n",
    "K > 3 + \\frac{5}{3}S^2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mean: $\\mu = \\eta + \\delta\\frac{\\beta}{\\varphi}$\n",
    "\n",
    "* Variance: $\\sigma^2 = \\delta\\frac{\\alpha^2}{\\varphi^3}$\n",
    "\n",
    "* Skew: $S = 3\\frac{\\beta}{\\alpha \\sqrt{\\delta\\varphi}}$\n",
    "\n",
    "* Kurtosis: $K = 3 + \\frac{3}{\\delta\\varphi}\\left( 1 + 4\\left(\\frac{\\beta}{\\alpha} \\right)^2 \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "ASKSR &= \\sqrt{2\\left(\\lambda a^*(\\eta - r) -\\delta\\left (\\varphi - \\sqrt{\\alpha^2 - (\\beta - \\lambda a^*)^2}\\right)\\right)} \\\\\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "a^* &= \\frac{1}{\\lambda}\\left(\\beta + \\frac{\\alpha(\\eta - r)}{\\sqrt{\\delta^2 + (\\eta - r)^2}} \\right) \\\\\\\\\n",
    "\\varphi &= \\sqrt{\\alpha^2 - \\beta^2} \\\\\\\\\n",
    "\\alpha &= \\frac{3\\sqrt{a}}{\\sigma^2 b} \\\\\\\\\n",
    "\\beta &= \\frac{3S}{\\sigma b} \\\\\\\\\n",
    "\\eta &= \\mu - \\frac{3S\\sigma}{a} \\\\\\\\\n",
    "\\delta &= 3\\sigma\\frac{\\sqrt{b}}{a} \\\\\\\\\n",
    "a &= 3K - 4S^2 - 9 \\\\\\\\\n",
    "b &= 3K - 5S^2 - 9 \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the generalized skew-kurtosis Sharpe Ratio as explained in \n",
    "# \"Portfolio performance evaluation with generalized Sharpe ratios: \n",
    "# Beyond the mean and variance\" (Zakamouline and Koekebakker, 2008).\n",
    "\n",
    "# returns_data: DataFrame with Timestamp indices and daily pct change.\n",
    "# window: size of rolling window.\n",
    "def asksr(returns_data, window=30):\n",
    "    \n",
    "    # Create a dataframe in which to store ASKSR and SR values and\n",
    "    # model assumptions required to verify the validity of ASKSR values.\n",
    "    sharpes = pd.DataFrame(\n",
    "        columns=['ASKSR', \n",
    "                 'SR', \n",
    "                 'Delta > 0', \n",
    "                 'Alpha > 0', \n",
    "                 'Beta/alpha < 1',\n",
    "                 'Kurtosis/Skewness'])\n",
    "    \n",
    "    # Use the U.S. Treasury long-term bill rate of return as the \"risk free rate\"\n",
    "    risk_free = q.get('USTREASURY/REALLONGTERM', start_date=start, end_date=end).dropna().pct_change()\n",
    "    risk_free_rolling = risk_free.rolling(window=30, min_periods=4).mean().dropna().values.tolist()\n",
    "    \n",
    "    # Generate a Rolling object over which to compute the rolling statistical moments.\n",
    "    rolling = returns_data.rolling(window=30, min_periods=4)\n",
    "    mean = rolling.mean().dropna()\n",
    "    var = rolling.var().dropna()\n",
    "    std = rolling.std().dropna()\n",
    "    skew = rolling.apply(lambda x : stats.skew(x), raw=True).dropna()\n",
    "    kurt = rolling.apply(lambda x : stats.kurtosis(x), raw=True).dropna()\n",
    "\n",
    "    # For each set of rolling values per date, compute the parameters describing ASKSR.\n",
    "    for m, v, st, sk, ku, r, date in zip(mean, var, std, skew, kurt, risk_free_rolling, returns_data.index):\n",
    "        \n",
    "        a = 3*ku - 4*(sk**2)-9\n",
    "        b = 3*ku - 5*(sk**2)-9\n",
    "        alpha = (3*c.sqrt(a))/(v*b)\n",
    "        beta = (3*sk)/(c.sqrt(v)*b)\n",
    "        eta = m - (3*sk*c.sqrt(v))/(a)\n",
    "        sigma = 3*c.sqrt(v)*(c.sqrt(b)/a)\n",
    "        phi = c.sqrt(alpha**2 - beta**2)\n",
    "        delta = (m - eta)*(phi/beta)\n",
    "        a_star = beta + (alpha*(eta - r[0]))/(c.sqrt(delta**2 + (eta - r[0])**2))\n",
    "\n",
    "        # cmath library is used to handle complex values (unsure if this should be expected).\n",
    "        ASKSR = c.sqrt(2*(a_star*(eta - r[0]) - delta*(\n",
    "            phi - c.sqrt(alpha**2 - (beta - a_star)**2))))*c.sqrt(window)\n",
    "        ASKSR_mag = ASKSR.real**2 + ASKSR.imag**2\n",
    "        SR = ((m - r[0])/(np.sqrt(v) - r[0]))*np.sqrt(window)\n",
    "        \n",
    "        # Generate a Pandas Series to append to the sharpes dataframe.\n",
    "        row = pd.Series([float('%.3f'%(ASKSR_mag)), \n",
    "                        float('%.3f'%(SR)), \n",
    "                        str(delta.real > 0),\n",
    "                        str(alpha.real > 0), \n",
    "                        str((np.abs(beta)/alpha) < 1), \n",
    "                        str(ku > (5/3)*(sk**2) + 3)], \n",
    "                       index=sharpes.columns).rename(date)\n",
    "        sharpes = sharpes.append(row)\n",
    "    \n",
    "    return sharpes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe in which to store pct returns of all stocks in port.\n",
    "p = pd.DataFrame()\n",
    "\n",
    "# For each stock, extract the percent change and add it to p.\n",
    "for tick, data in port_rets.items():\n",
    "    p[tick] = data['pct change']\n",
    "\n",
    "# Calculate the net return of the portfolio after each trading day.\n",
    "p['net'] = p.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = asksr(p['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the ASKSR readings tend to be much greater than the standard SR and has a tendency to become extremely large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.plot(figsize=(15,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZUO (1yr and 1mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = 'ZUO'\n",
    "\n",
    "# Enter start date\n",
    "start = '2018-04-21'\n",
    "\n",
    "# Default set to today\n",
    "end = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "ti = ti_dct[0]\n",
    "\n",
    "macd, macd_meta = ti.get_macd(stock)\n",
    "macd = pd.DataFrame(macd)\n",
    "macd.index = pd.to_datetime(macd.index)\n",
    "\n",
    "rsi, rsi_meta = ti.get_rsi(stock)\n",
    "rsi = pd.DataFrame(rsi)\n",
    "rsi.index = pd.to_datetime(rsi.index)\n",
    "\n",
    "boll, boll_meta = ti.get_bbands(stock, time_period=60)\n",
    "boll = pd.DataFrame(boll)\n",
    "boll.index = pd.to_datetime(boll.index)\n",
    "\n",
    "ad, ad_meta = ti.get_ad(stock)\n",
    "ad = pd.DataFrame(ad)\n",
    "ad.index = pd.to_datetime(ad.index)\n",
    "\n",
    "obv, obv_meta = ti.get_obv(stock)\n",
    "obv = pd.DataFrame(obv)\n",
    "obv.index = pd.to_datetime(obv.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (15,3)\n",
    "port['ZUO']['close'][start:end].plot(title='Close Price', figsize=size)\n",
    "macd[start:end].plot(title= 'MACD', figsize=size);\n",
    "rsi[start:end].plot(title='RSI', figsize=size);\n",
    "boll[start:end].plot(title='Bollinger Bands', figsize=size);\n",
    "ad[start:end].plot(title='Chaikin A/D Line', figsize=size);\n",
    "obv[start:end].plot(title='On-Balance Volume', figsize=size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '2019-03-21'\n",
    "\n",
    "size = (15,3)\n",
    "port['ZUO']['close'][start:end].plot(title='Close Price', figsize=size)\n",
    "macd[start:end].plot(title= 'MACD', figsize=size);\n",
    "rsi[start:end].plot(title='RSI', figsize=size);\n",
    "boll[start:end].plot(title='Bollinger Bands', figsize=size);\n",
    "ad[start:end].plot(title='Chaikin A/D Line', figsize=size);\n",
    "obv[start:end].plot(title='On-Balance Volume', figsize=size);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(mean-r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eff_rat(symbol, period=7):\n",
    "    close_data = port[symbol]['close']\n",
    "    close\n",
    "    \n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "close_data = port['EPD']['close']\n",
    "\n",
    "abs_change = close_data.diff().resample('7D').sum()\n",
    "#summed_data = close_data.resample('7D')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
